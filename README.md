# WeRateDogs Twitter Archive Data Wrangling Project

This project involves downloading the twitter archive of user WeRateDogs and gathering, assessing and cleaning the data (data wrangling process) to obtain clean data and analyse the data further to gain interesting insights. 

The Data Gathering process involved obtaining data from three different sources. We had to download the twitter archive file directly and import into a dataframe. The image predictions file was made available on Udacity's server. We had to use Requests library and code to download the file and save the data into a new file. Finally we had to use Twitter API called Tweepy to obtain the JSON data of each tweet and save it to a file. We have to parse through the file to extract some more tweet information and save this to a CSV file which we finally read into another dataframe.

The Data Assessing process involved physically viewing the data in each of the dataframe and programmatically researching through various data to assess the issues that eexist related to data quality or structure or tidyness.

